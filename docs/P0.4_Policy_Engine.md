"""
x0tta6bl4 P0.4 Policy Engine - Comprehensive Documentation
==========================================================

## Overview

P0.4 Policy Engine enables autonomous decision-making in the x0tta6bl4 mesh network.
It evaluates incidents against predefined policies and triggers appropriate recovery actions.

**Key Features:**
- REST API for policy CRUD operations
- Event-driven policy evaluation via RabbitMQ
- Audit trail for compliance and debugging
- Integration with P0.1 Monitor and P0.3 Recovery Planner
- Template-based policy definitions

---

## Architecture

```
┌─────────────┐      ┌──────────────────┐      ┌─────────────────┐
│ P0.1 Monitor│─────▶│ P0.4 Policy      │─────▶│ P0.3 Recovery   │
│  (Events)   │      │   Engine API     │      │   Planner       │
└─────────────┘      │                  │      └─────────────────┘
                     │  ┌─────────────┐ │
                     │  │ PolicyStore │ │
                     │  │ (PostgreSQL)│ │
                     │  └─────────────┘ │
                     │                  │
                     │  ┌─────────────┐ │
                     │  │EventConsumer│ │
                     │  │ (RabbitMQ)  │ │
                     │  └─────────────┘ │
                     └──────────────────┘
```

**Components:**

1. **PolicyStore**: PostgreSQL database with Policy and PolicyEvaluation tables
2. **PolicyEngine**: Core evaluation logic with condition matching
3. **REST API**: FastAPI endpoints for policy management
4. **EventConsumer**: RabbitMQ listener for incident events
5. **Audit Log**: PolicyEvaluation table tracks all evaluations

---

## Database Schema

### Policy Table

| Column       | Type     | Description                          |
|--------------|----------|--------------------------------------|
| id           | Integer  | Primary key                          |
| name         | String   | Unique policy name                   |
| description  | String   | Human-readable description           |
| definition   | JSON     | Policy definition (condition/action) |
| active       | Boolean  | Enable/disable policy                |
| priority     | Integer  | Evaluation priority (higher = first) |
| created_at   | DateTime | Creation timestamp                   |
| updated_at   | DateTime | Last modification timestamp          |

### PolicyEvaluation Table (Audit Log)

| Column            | Type     | Description                    |
|-------------------|----------|--------------------------------|
| id                | Integer  | Primary key                    |
| policy_id         | Integer  | Foreign key to Policy          |
| event_id          | String   | Incident event ID              |
| input_data        | JSON     | Event payload                  |
| result            | JSON     | Evaluation result              |
| execution_time_ms | Float    | Evaluation duration            |
| created_at        | DateTime | Evaluation timestamp           |

---

## Policy Definition Format

Policies are defined using JSON with the following structure:

```json
{
  "condition": "incident.type == 'memory_leak' and incident.severity >= 8",
  "action": "trigger_p0_3_recovery",
  "modifiers": {
    "swap_increase": "2x",
    "threshold": 90
  },
  "reversibility_sec": 300
}
```

**Fields:**

- **condition**: Python expression evaluated against incident data
- **action**: Action identifier (e.g., `trigger_p0_3_recovery`, `scale_horizontal`)
- **modifiers**: Action parameters (passed to P0.3 Recovery Planner)
- **reversibility_sec**: Rollback timeout in seconds

**Example Conditions:**

```python
# Memory leak detection
"incident.type == 'memory_leak' and incident.severity >= 8"

# CPU spike with high load
"incident.type == 'cpu_spike' and incident.context.load_avg > 10.0"

# Disk full critical
"incident.type == 'disk_full' and incident.context.usage_percent >= 95"

# Network latency threshold
"incident.type == 'network_latency' and incident.context.latency_ms > 500"
```

---

## REST API Reference

### Base URL

```
http://localhost:8004
```

### Endpoints

#### 1. Create Policy

**POST** `/policies`

**Request Body:**

```json
{
  "name": "memory_leak_recovery",
  "description": "Trigger recovery on memory leak",
  "definition": {
    "condition": "incident.type == 'memory_leak' and incident.severity >= 8",
    "action": "trigger_p0_3_recovery",
    "modifiers": {"swap": "2x"},
    "reversibility_sec": 300
  },
  "active": true,
  "priority": 10
}
```

**Response:** `201 Created`

```json
{
  "id": 1,
  "name": "memory_leak_recovery",
  "description": "Trigger recovery on memory leak",
  "definition": {...},
  "active": true,
  "priority": 10,
  "created_at": "2025-10-20T12:00:00",
  "updated_at": "2025-10-20T12:00:00"
}
```

#### 2. List Policies

**GET** `/policies?active_only=true`

**Response:** `200 OK`

```json
[
  {
    "id": 1,
    "name": "memory_leak_recovery",
    "active": true,
    "priority": 10,
    ...
  },
  ...
]
```

#### 3. Get Policy

**GET** `/policies/{id}`

**Response:** `200 OK` (or `404 Not Found`)

#### 4. Update Policy

**PUT** `/policies/{id}`

**Request Body:**

```json
{
  "name": "updated_policy_name",
  "active": false
}
```

**Response:** `200 OK`

#### 5. Delete Policy

**DELETE** `/policies/{id}`

**Response:** `204 No Content`

#### 6. Evaluate Policies

**POST** `/evaluate`

**Request Body:**

```json
{
  "event_type": "memory_leak",
  "severity": 9,
  "context": {
    "service": "payment-api",
    "memory_usage_mb": 8192
  },
  "timestamp": "2025-10-20T12:00:00"
}
```

**Response:** `200 OK`

```json
[
  {
    "policy_id": 1,
    "policy_name": "memory_leak_recovery",
    "matched": true,
    "action": "trigger_p0_3_recovery",
    "execution_time_ms": 12.5
  },
  ...
]
```

#### 7. Health Check

**GET** `/health`

**Response:** `200 OK`

```json
{
  "status": "healthy",
  "timestamp": "2025-10-20T12:00:00"
}
```

---

## Event-Driven Evaluation

### EventConsumer Setup

The EventConsumer listens to RabbitMQ for incident events and automatically evaluates policies.

**Configuration:**

```python
class EventConsumerConfig:
    broker_url = "amqp://guest:guest@localhost:5672/"
    exchange = "mesh_events"
    queue = "policy_evaluation_queue"
    routing_keys = [
        "incident.detected",
        "anomaly.detected",
        "threshold.exceeded"
    ]
```

**Start Consumer:**

```bash
python src/p04_policies/event_consumer.py
```

**Event Flow:**

1. P0.1 Monitor detects incident → publishes event to RabbitMQ
2. EventConsumer receives event → evaluates all active policies
3. Matched policy → sends action to P0.3 Recovery Planner
4. Evaluation logged to PolicyEvaluation table

---

## Deployment

### 1. Install Dependencies

```bash
pip install -r requirements-p04.txt
```

### 2. Configure Database

Edit `alembic.ini`:

```ini
sqlalchemy.url = postgresql://user:pass@localhost:5432/mesh_policies
```

### 3. Run Migrations

```bash
# Initialize Alembic (first time only)
alembic revision --autogenerate -m "Initial P0.4 schema"

# Apply migrations
alembic upgrade head
```

### 4. Start API Server

```bash
uvicorn src.p04_policies.api:app --reload --port 8004
```

### 5. Start Event Consumer

```bash
python src/p04_policies/event_consumer.py
```

### 6. Load Example Policies

```bash
curl -X POST http://localhost:8004/policies \
  -H "Content-Type: application/json" \
  -d @src/p04_policies/config/policies.yaml
```

---

## Testing

### Run Unit Tests

```bash
PYTHONPATH=src pytest -v tests/unit/p04_policies/
```

### Run Integration Tests

```bash
PYTHONPATH=src pytest -v tests/integration/test_policy_flow.py
```

### Test Coverage

```bash
pytest --cov=src/p04_policies --cov-report=html
```

---

## Integration with MAPE-K Loop

P0.4 fits into the MAPE-K architecture as follows:

**Monitor (P0.1)** → **Analyze (P0.2)** → **Plan (P0.4 PolicyEngine)** → **Execute (P0.3 Recovery)** → **Knowledge (P0.2.6 RAG)**

**Event Flow:**

1. **P0.1 Monitor** detects anomaly → publishes `incident.detected` event
2. **P0.4 PolicyEngine** evaluates policies → selects best action
3. **P0.3 Recovery Planner** receives action → generates recovery plan
4. **P0.3 Executor** executes plan → restores service
5. **P0.2.6 RAG KB** stores incident pattern → improves future detection

---

## Performance Optimization

### Redis Caching (Planned)

Cache frequently evaluated policies:

```python
# Cache policy evaluation results for 60s
redis_client.setex(f"policy:{policy_id}:result", 60, json.dumps(result))
```

### Policy Priority

Higher priority policies evaluated first:

```sql
SELECT * FROM policies WHERE active = true ORDER BY priority DESC;
```

### Batch Evaluation

Evaluate multiple events in parallel:

```python
async def evaluate_batch(events: List[PolicyInput]):
    tasks = [evaluate_policies(event) for event in events]
    return await asyncio.gather(*tasks)
```

---

## Security Considerations

⚠️ **CRITICAL**: Current implementation uses `eval()` for condition evaluation, which is **UNSAFE** in production.

**Production Solution:**

Replace `eval()` with safe expression parser:

```python
from jinja2 import Environment

env = Environment()
template = env.from_string("{{ incident.type == 'memory_leak' }}")
result = template.render(incident=incident_data)
```

**Additional Security:**

- Implement authentication/authorization on REST API
- Use HTTPS/TLS for API endpoints
- Validate policy definitions before saving
- Rate limit `/evaluate` endpoint to prevent DoS

---

## Monitoring & Observability

### Prometheus Metrics

```python
from prometheus_client import Counter, Histogram

policy_evaluations = Counter('policy_evaluations_total', 'Total evaluations', ['policy_name'])
evaluation_duration = Histogram('policy_evaluation_duration_seconds', 'Evaluation time')
```

### Grafana Dashboard

Key metrics to track:

- Policies evaluated per minute
- Average evaluation time
- Match rate (matched/total)
- Action execution rate
- Error rate

---

## Troubleshooting

### Issue: Policies not matching

**Diagnosis:**

```bash
# Check policy definitions
curl http://localhost:8004/policies

# Check evaluation logs
SELECT * FROM policy_evaluations ORDER BY created_at DESC LIMIT 10;
```

**Solution:**

- Verify condition syntax
- Check incident data format
- Enable debug logging in policy_engine.py

### Issue: EventConsumer not receiving events

**Diagnosis:**

```bash
# Check RabbitMQ connection
rabbitmqctl list_queues

# Check routing keys
rabbitmqctl list_bindings
```

**Solution:**

- Verify RabbitMQ is running
- Check broker_url in config
- Ensure P0.1 Monitor is publishing events

---

## Roadmap

- [ ] Replace `eval()` with Jinja2 templating
- [ ] Implement Redis caching for policy results
- [ ] Add authentication/authorization
- [ ] Create Grafana dashboard
- [ ] Implement distributed policy evaluation (mesh-wide)
- [ ] Add policy versioning and rollback
- [ ] Create policy simulation/dry-run mode
- [ ] Integrate with P0.2.6 RAG KB for historical context

---

## References

- **P0.3 Recovery Planner**: `docs/P0.3_Recovery_Planner.md`
- **P0.2.6 RAG KB**: `P0_2_6_COMPLETION.md`
- **FastAPI Docs**: https://fastapi.tiangolo.com/
- **Pydantic Validation**: https://docs.pydantic.dev/
- **RabbitMQ Tutorial**: https://www.rabbitmq.com/getstarted.html

---

**Version**: 1.0.0  
**Status**: DEVELOPMENT  
**Last Updated**: 2025-10-20
